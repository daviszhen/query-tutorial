{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "outputs": [],
   "source": [
    "from pglast import ast,parser,visitors,printers,enums\n",
    "from pprint import pprint\n",
    "import pyarrow as arrow\n",
    "from pyarrow import csv,compute,types\n",
    "import pandas\n",
    "from datetime import datetime,timedelta,date\n",
    "import hashlib"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 设置数据源"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 设置lineitem的数据源"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "outputs": [],
   "source": [
    "lineitem_path = \"/Users/pengzhen/Documents/GitHub/mo-test/tpch100M/lineitem.tbl_100\"\n",
    "lineitem_delimiter = \"|\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 初始化表lineitem的schema"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "outputs": [],
   "source": [
    "# create table lineitem ( l_orderkey    bigint not null,\n",
    "#                              l_partkey     integer not null,\n",
    "#                              l_suppkey     integer not null,\n",
    "#                              l_linenumber  integer not null,\n",
    "#                              l_quantity    decimal(15,2) not null,\n",
    "#                              l_extendedprice  decimal(15,2) not null,\n",
    "#                              l_discount    decimal(15,2) not null,\n",
    "#                              l_tax         decimal(15,2) not null,\n",
    "#                              l_returnflag  varchar(1) not null,\n",
    "#                              l_linestatus  varchar(1) not null,\n",
    "#                              l_shipdate    date not null,\n",
    "#                              l_commitdate  date not null,\n",
    "#                              l_receiptdate date not null,\n",
    "#                              l_shipinstruct varchar(25) /*char(25)*/ not null,\n",
    "#                              l_shipmode     varchar(10) /*char(10)*/ not null,\n",
    "#                              l_comment      varchar(44) not null,\n",
    "#                          primary key (l_orderkey, l_linenumber)\n",
    "#                         );"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "outputs": [],
   "source": [
    "lineitemSchema = arrow.schema([\n",
    "    arrow.field(\"l_orderkey\",arrow.int64(),False),\n",
    "    arrow.field(\"l_partkey\",arrow.int32(),False),\n",
    "    arrow.field(\"l_suppkey\",arrow.int32(),False),\n",
    "    arrow.field(\"l_linenumber\",arrow.int32(),False),\n",
    "    arrow.field(\"l_quantity\",arrow.decimal256(21,2),False),\n",
    "    arrow.field(\"l_extendedprice\",arrow.decimal256(21,2),False),\n",
    "    arrow.field(\"l_discount\",arrow.decimal256(21,2),False),\n",
    "    arrow.field(\"l_tax\",arrow.decimal256(21,2),False),\n",
    "    arrow.field(\"l_returnflag\",arrow.utf8(),False),\n",
    "    arrow.field(\"l_linestatus\",arrow.utf8(),False),\n",
    "    arrow.field(\"l_shipdate\",arrow.date32(),False),\n",
    "    arrow.field(\"l_commitdate\",arrow.date32(),False),\n",
    "    arrow.field(\"l_receiptdate\",arrow.date32(),False),\n",
    "    arrow.field(\"l_shipinstruct\",arrow.utf8(),False),\n",
    "    arrow.field(\"l_shipmode\",arrow.utf8(),False),\n",
    "    arrow.field(\"l_comment\",arrow.utf8(),False),\n",
    "],{\"name\":\"lineitem\",\n",
    "   \"delimiter\":lineitem_delimiter,\n",
    "   \"path\":lineitem_path})\n",
    "# lineitemSchema"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 定义常量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "outputs": [],
   "source": [
    "\n",
    "# logical plan 标签\n",
    "RELATIONS = \"relations\"\n",
    "SINGLE_RELATION = \"singleRelation\"\n",
    "MULTI_RELATION = \"multipleRelation\"\n",
    "WHERE = \"where\"\n",
    "OUTPUT = \"output\"\n",
    "GROUP = \"group\"\n",
    "ORDER = \"order\"\n",
    "AGGREGATE = \"aggregate\"\n",
    "PROJECT = \"project\"\n",
    "\n",
    "RELATION_TYPE_IDX = 0\n",
    "DB_NAME_IDX = 1\n",
    "ALIAS_IDX = 2\n",
    "TABLE_NAME_IDX = 3\n",
    "SCHEMA_IDX = 4\n",
    "\n",
    "RELATION_TYPE_TABLE = \"table\"\n",
    "RELATION_TYPE_VIEW = \"view\"\n",
    "RELATION_TYPE_SUBQUERY = \"subquery\"\n",
    "\n",
    "EXPR_OP_COLUMN_REF = \"colRef\"\n",
    "EXPR_OP_LESS_EQUAL = \"<=\"\n",
    "EXPR_OP_PLUS = \"+\"\n",
    "EXPR_OP_MINUS = \"-\"\n",
    "EXPR_OP_MULTI = \"*\"\n",
    "EXPR_OP_CAST = \"cast\"\n",
    "EXPR_OP_CONST = \"const\"\n",
    "\n",
    "FUNC_EXPR = \"func\"\n",
    "FUNC_RESULT_REF_EXPR = \"func_result_ref\"\n",
    "OUTPUT_EXPR = \"output_expr\"\n",
    "GROUP_EXPR = \"group_expr\"\n",
    "ORDER_EXPR = \"order_expr\"\n",
    "PROJECT_EXPR = \"project_expr\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 初始化Catalog"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "outputs": [
    {
     "data": {
      "text/plain": "{'tpch': {'lineitem': l_orderkey: int64 not null\n  l_partkey: int32 not null\n  l_suppkey: int32 not null\n  l_linenumber: int32 not null\n  l_quantity: decimal256(21, 2) not null\n  l_extendedprice: decimal256(21, 2) not null\n  l_discount: decimal256(21, 2) not null\n  l_tax: decimal256(21, 2) not null\n  l_returnflag: string not null\n  l_linestatus: string not null\n  l_shipdate: date32[day] not null\n  l_commitdate: date32[day] not null\n  l_receiptdate: date32[day] not null\n  l_shipinstruct: string not null\n  l_shipmode: string not null\n  l_comment: string not null\n  -- schema metadata --\n  name: 'lineitem'\n  delimiter: '|'\n  path: '/Users/pengzhen/Documents/GitHub/mo-test/tpch100M/lineitem.tbl_100'}}"
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Catalog = {\n",
    "    \"tpch\":{\n",
    "        \"lineitem\":lineitemSchema\n",
    "    }\n",
    "}\n",
    "\n",
    "def isValidName(s):\n",
    "    return not (s is None or len(s) == 0)\n",
    "\n",
    "\n",
    "def getColumn(plan,dbName,tableName,colName):\n",
    "    \"\"\"取列定义\"\"\"\n",
    "    relations = plan.get(RELATIONS,None)\n",
    "    if relations is None:\n",
    "        raise Exception(\"no table defs\")\n",
    "\n",
    "    if len(dbName) == 0:\n",
    "        dbName = \"tpch\"\n",
    "\n",
    "    if relations[0] == SINGLE_RELATION:\n",
    "        single = relations[1]\n",
    "        if len(tableName) == 0:\n",
    "            #print(f\"single {single}\")\n",
    "            for tableName2,tableDef in single.items():\n",
    "                schema = tableDef[SCHEMA_IDX]\n",
    "                colDef = schema.field(colName)\n",
    "                if colDef is not None:\n",
    "                    return colDef,dbName,tableName2\n",
    "            raise Exception(f\"no column name {colName} in table {tableName}\")\n",
    "\n",
    "        if tableName in single:\n",
    "            tableDef = single[tableName]\n",
    "            if tableDef[DB_NAME_IDX] == dbName and tableDef[ALIAS_IDX] == tableName:\n",
    "                schema = tableDef[SCHEMA_IDX]\n",
    "                colDef = schema.field(colName)\n",
    "                if colDef is not None:\n",
    "                    return colDef,dbName,tableName\n",
    "                else:\n",
    "                    raise Exception(f\"no column name {colName} in table {tableName}\")\n",
    "            else:\n",
    "                raise Exception(f\"invalid database name {dbName} or table name {tableName}\")\n",
    "        else:\n",
    "            raise Exception(f\"no such relation {tableName} in database {dbName}\")\n",
    "    else:\n",
    "        raise Exception(\"not implement multiple relations\")\n",
    "\n",
    "\n",
    "\n",
    "Catalog"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 取tpch q1 ast"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "outputs": [],
   "source": [
    "q1Stmt = parser.parse_sql(\n",
    "    \"select \\\n",
    "        l_returnflag, \\\n",
    "        l_linestatus, \\\n",
    "        sum(l_quantity) as sum_qty, \\\n",
    "        sum(l_extendedprice) as sum_base_price, \\\n",
    "        sum(l_extendedprice * (1 - l_discount)) as sum_disc_price, \\\n",
    "        sum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) as sum_charge, \\\n",
    "        avg(l_quantity) as avg_qty, \\\n",
    "        avg(l_extendedprice) as avg_price, \\\n",
    "        avg(l_discount) as avg_disc, \\\n",
    "        count(*) as count_order \\\n",
    "    from \\\n",
    "        lineitem \\\n",
    "    where \\\n",
    "        l_shipdate <= date '1998-12-01' - interval '112' day \\\n",
    "    group by \\\n",
    "        l_returnflag, \\\n",
    "        l_linestatus \\\n",
    "    order by \\\n",
    "        l_returnflag, \\\n",
    "        l_linestatus;\"\n",
    ")[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "outputs": [],
   "source": [
    "#q1Stmt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 构建tpch q1的逻辑查询计划"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 逻辑查询计划builder\n",
    "\n",
    "从各种SQL语句构建逻辑查询计划\n",
    "\n",
    "逻辑查询计划定义为字典类型。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "outputs": [],
   "source": [
    "class LogicalPlanBuilder:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def build(self,node,plan : dict):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## select语句builder\n",
    "\n",
    "为select语句生成逻辑查询计划。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "outputs": [],
   "source": [
    "class SelectBuilder(LogicalPlanBuilder):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self,select : ast.SelectStmt,plan : dict):\n",
    "        fb = FromBuilder()\n",
    "        fb.build(select.fromClause,plan)\n",
    "\n",
    "        wb = WhereBuilder()\n",
    "        wb.build(select.whereClause,plan)\n",
    "\n",
    "        selectList = SelectListBuilder()\n",
    "        selectList.build(select.targetList,plan)\n",
    "\n",
    "        groupby = GroupbyBuilder()\n",
    "        groupby.build(select.groupClause,plan)\n",
    "\n",
    "        orderby = OrderbyBuilder()\n",
    "        orderby.build(select.sortClause,plan)\n",
    "\n",
    "        project =  ProjectListBuilder()\n",
    "        project.build(select.targetList,plan)\n",
    "\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## from子句builder\n",
    "\n",
    "从from子句中提取各个关系表。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "outputs": [],
   "source": [
    "class FromBuilder(LogicalPlanBuilder):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def build(self,tableRefs : tuple,plan : dict):\n",
    "        #print(\"tableRefs\")\n",
    "        if len(tableRefs) == 1:\n",
    "            single = self.buildTableRef(tableRefs[0])\n",
    "            plan[RELATIONS] = [SINGLE_RELATION,single]\n",
    "            return\n",
    "        raise Exception(\"unsupport multiple table refs\")\n",
    "        pass\n",
    "\n",
    "    def buildTableRef(self,tableRef : ast.RangeVar)-> dict:\n",
    "        #print(\"tableRef\")\n",
    "        dbName = tableRef.schemaname\n",
    "        if dbName is None or len(dbName) == 0:\n",
    "            dbName = \"tpch\"\n",
    "\n",
    "        #print(Catalog[dbName])\n",
    "        if tableRef.relname in Catalog[dbName] :\n",
    "            return {tableRef.relname :\n",
    "                    [RELATION_TYPE_TABLE, #relation type\n",
    "                    dbName, #database name\n",
    "                    tableRef.relname,#alias=\n",
    "                    tableRef.relname,#original name\n",
    "                    Catalog[dbName][tableRef.relname] #schema\n",
    "                    ]}\n",
    "        else:\n",
    "            raise Exception(\"no such table in Catalog\",tableRef.schemaname,tableRef.relname)\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 表达式builder\n",
    "\n",
    "表达式构建基类。也是最复杂的类。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "outputs": [],
   "source": [
    "class ExpressionBuilder(LogicalPlanBuilder):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self,node,plan : dict):\n",
    "        if isinstance(node,ast.A_Expr):\n",
    "            if node.kind == enums.parsenodes.A_Expr_Kind.AEXPR_OP:\n",
    "                opName = node.name[0].sval\n",
    "                if opName == \"<=\":\n",
    "                    l = self.build(node.lexpr,plan)\n",
    "                    r = self.build(node.rexpr,plan)\n",
    "                    return EXPR_OP_LESS_EQUAL,l,r\n",
    "                elif opName == \"-\":\n",
    "                    l = self.build(node.lexpr,plan)\n",
    "                    r = self.build(node.rexpr,plan)\n",
    "                    return EXPR_OP_MINUS,l,r\n",
    "                elif opName == \"*\":\n",
    "                    l = self.build(node.lexpr,plan)\n",
    "                    r = self.build(node.rexpr,plan)\n",
    "                    return EXPR_OP_MULTI,l,r\n",
    "                elif opName == \"+\":\n",
    "                    l = self.build(node.lexpr,plan)\n",
    "                    r = self.build(node.rexpr,plan)\n",
    "                    return EXPR_OP_PLUS,l,r\n",
    "                else:\n",
    "                    raise Exception(\"unsupported operator\",node)\n",
    "            else:\n",
    "                raise Exception(\"unsupported expr 1\",node)\n",
    "        elif isinstance(node,ast.ColumnRef):\n",
    "            fields = node.fields\n",
    "            if len(fields) == 1:\n",
    "                colName = fields[0].sval\n",
    "                #print(f\"{fields}, {colName}\")\n",
    "                colRef = getColumn(plan,\"\",\"\",colName)\n",
    "                return EXPR_OP_COLUMN_REF, colRef\n",
    "            raise Exception(\"unsupported column ref\",node)\n",
    "        elif isinstance(node,ast.TypeCast):\n",
    "            #print(f\"type_cast {node.arg} \\nto_type {node.typeName}\")\n",
    "\n",
    "            e = self.build(node.arg,plan)\n",
    "            t = node.typeName.names\n",
    "            return EXPR_OP_CAST,e,t\n",
    "        elif isinstance(node,ast.A_Const):\n",
    "            if node.isnull:\n",
    "                return EXPR_OP_CONST,node.isnull\n",
    "            return EXPR_OP_CONST,node.isnull,node.val\n",
    "        elif isinstance(node,ast.FuncCall):\n",
    "            # pprint(node)\n",
    "            func_name = node.funcname[0].sval\n",
    "            is_agg_func = False\n",
    "            if is_aggregate_func(func_name):\n",
    "                is_agg_func = True\n",
    "            args = None\n",
    "            if node.args is not None:\n",
    "                args = []\n",
    "                for arg in node.args:\n",
    "                    arg_e = self.build(arg,plan)\n",
    "                    args.append(arg_e)\n",
    "            elif node.agg_star:\n",
    "                args = \"*\"\n",
    "            else:\n",
    "                raise Exception(\"function has no args\",node)\n",
    "            if is_agg_func:\n",
    "                # print(f\"agg func {func_name}\")\n",
    "                aggs = plan.get(AGGREGATE,[])\n",
    "                agg_idx = len(aggs)\n",
    "                aggs.append((FUNC_EXPR,func_name,args))\n",
    "                plan[AGGREGATE] = aggs\n",
    "                return FUNC_RESULT_REF_EXPR,agg_idx\n",
    "            return FUNC_EXPR,func_name,args\n",
    "        else:\n",
    "            raise Exception(\"unsupported expr 2\",node)\n",
    "        pass\n",
    "\n",
    "\n",
    "def is_aggregate_func(name):\n",
    "    return name in [\"count\",\"avg\",\"sum\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## where子句builder\n",
    "\n",
    "构建where表达式。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "outputs": [],
   "source": [
    "class WhereBuilder(LogicalPlanBuilder):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self,node,plan : dict):\n",
    "        #print(\"where \",node)\n",
    "        eb = ExpressionBuilder()\n",
    "        ret = eb.build(node,plan)\n",
    "        plan[WHERE] = ret"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## select expr builder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "outputs": [],
   "source": [
    "class SelectExprBuilder(ExpressionBuilder):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self,node,plan : dict):\n",
    "        if isinstance(node,ast.ResTarget):\n",
    "            value = node.val\n",
    "            if isinstance(value,ast.ColumnRef):\n",
    "                r = super().build(value,plan)\n",
    "                #print(f\"-->{r}\")\n",
    "                alias = node.name\n",
    "                if not isValidName(alias):\n",
    "                    #取列名\n",
    "                    alias = r[1][0].name\n",
    "                return OUTPUT_EXPR, alias, r\n",
    "            elif isinstance(value,ast.FuncCall):\n",
    "                r = super().build(value,plan)\n",
    "                alias = node.name\n",
    "                if not isValidName(alias):\n",
    "                    #取表达式字符串\n",
    "                    alias = str(value)\n",
    "                return OUTPUT_EXPR,alias,r\n",
    "            else:\n",
    "                return super().build(value,plan)\n",
    "        else:\n",
    "            return super().build(node,plan)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## select list builder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "outputs": [],
   "source": [
    "\n",
    "class SelectListBuilder(LogicalPlanBuilder):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self,node,plan : dict):\n",
    "        #print(\"select list\",node)\n",
    "        #pprint(node)\n",
    "        selExprBuilder = SelectExprBuilder()\n",
    "        output = []\n",
    "        for expr in node:\n",
    "            #pprint(expr)\n",
    "            o = selExprBuilder.build(expr,plan)\n",
    "            output.append(o)\n",
    "        plan[OUTPUT] = output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## group expr builder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "outputs": [],
   "source": [
    "class GroupExprBuilder(ExpressionBuilder):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self,node,plan : dict):\n",
    "        r = super().build(node,plan)\n",
    "        return GROUP_EXPR,r"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## group by子句builder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "outputs": [],
   "source": [
    "class GroupbyBuilder(LogicalPlanBuilder):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self,node,plan : dict):\n",
    "        geb = GroupExprBuilder()\n",
    "        groupby = []\n",
    "        for expr in node:\n",
    "            r = geb.build(expr,plan)\n",
    "            groupby.append(r)\n",
    "        plan[GROUP] = groupby\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## order expr builder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "outputs": [],
   "source": [
    "class OrderExprBuilder(ExpressionBuilder):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self,node,plan : dict):\n",
    "        if isinstance(node,ast.SortBy):\n",
    "            r = super().build(node.node,plan)\n",
    "            return ORDER_EXPR,r,node.sortby_dir\n",
    "        else:\n",
    "            raise Exception(f\"not implement order expr {node}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## order by builder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "outputs": [],
   "source": [
    "class OrderbyBuilder(LogicalPlanBuilder):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self,node,plan : dict):\n",
    "        oeb = OrderExprBuilder()\n",
    "        orderby = []\n",
    "        for expr in node:\n",
    "            r = oeb.build(expr,plan)\n",
    "            orderby.append(r)\n",
    "        plan[ORDER] = orderby\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## project expr builder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "outputs": [],
   "source": [
    "class ProjectExprBuilder(ExpressionBuilder):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self,node,plan : dict):\n",
    "        if isinstance(node,ast.ResTarget):\n",
    "            value = node.val\n",
    "            if isinstance(value,ast.ColumnRef):\n",
    "                r = super().build(value,plan)\n",
    "                alias = node.name\n",
    "                if not isValidName(alias):\n",
    "                    #取列名\n",
    "                    alias = r[1][0].name\n",
    "                return PROJECT_EXPR, alias\n",
    "            elif isinstance(value,ast.FuncCall):\n",
    "                r = super().build(value,plan)\n",
    "                alias = node.name\n",
    "                if not isValidName(alias):\n",
    "                    #取表达式字符串\n",
    "                    alias = str(value)\n",
    "                return PROJECT_EXPR,alias\n",
    "            else:\n",
    "                return super().build(value,plan)\n",
    "        else:\n",
    "            return super().build(node,plan)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## project list builder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "outputs": [],
   "source": [
    "class ProjectListBuilder(LogicalPlanBuilder):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self,node,plan : dict):\n",
    "        projectExprBuilder = ProjectExprBuilder()\n",
    "        projects = []\n",
    "        for expr in node:\n",
    "            p = projectExprBuilder.build(expr,plan)\n",
    "            projects.append(p)\n",
    "        plan[PROJECT] = projects"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 构建tpch q1的物理查询计划"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 物理计划builder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "outputs": [],
   "source": [
    "class PhysicalPlanBuilder:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def build(self,plan : dict,node : str):\n",
    "        if node == RELATIONS:\n",
    "            rel_info = plan.get(RELATIONS)\n",
    "            if rel_info[0] == SINGLE_RELATION:\n",
    "                rel_def = rel_info[1]\n",
    "                table_name = list(rel_def.keys())[0]\n",
    "                table_def = rel_def.get(table_name)\n",
    "                schema = table_def[SCHEMA_IDX]\n",
    "                return CsvTableScan(schema,None,[16])\n",
    "            else:\n",
    "                raise Exception(f\"not implement relations {rel_info[0]}\")\n",
    "\n",
    "        elif node == WHERE :\n",
    "            child = self.build(plan,RELATIONS)\n",
    "            # 生成filter执行器\n",
    "            filter = plan.get(WHERE)\n",
    "            filter_exec = FilterExecutor(filter,child)\n",
    "            return filter_exec\n",
    "        elif node == GROUP:\n",
    "            child = self.build(plan,WHERE)\n",
    "            # 生成groupby执行器\n",
    "            groupby = GroupbyExecutor(plan,child)\n",
    "            return groupby\n",
    "        elif node == ORDER:\n",
    "            child = self.build(plan,GROUP)\n",
    "            orderby = OrderbyExecutor(plan,child)\n",
    "            return orderby\n",
    "        elif node == PROJECT:\n",
    "            child = self.build(plan,ORDER)\n",
    "            project = ProjectListExecutor(plan,child)\n",
    "            return project\n",
    "        else:\n",
    "            raise Exception(f\"not implement plan\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 物理执行计划执行器"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "outputs": [],
   "source": [
    "class Executor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def Open(self):\n",
    "        pass\n",
    "\n",
    "    def Next(self):\n",
    "        pass\n",
    "\n",
    "    def Close(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## csv table scan执行器"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "outputs": [],
   "source": [
    "class CsvTableScan(Executor):\n",
    "    def __init__(self,schema : arrow.Schema,column_names : list,drop_columns : list):\n",
    "        super().__init__()\n",
    "        self.reader = None\n",
    "        self.schema = schema\n",
    "        self.column_names = column_names\n",
    "        self.drop_columns = drop_columns\n",
    "        self.block_size = 16 * 1024\n",
    "\n",
    "    def Open(self):\n",
    "        # 打开文件\n",
    "        meta = self.schema.metadata\n",
    "        path = meta.get(b\"path\").decode('utf-8')\n",
    "        delimiter = meta.get(b\"delimiter\").decode('utf-8')\n",
    "        # pprint(meta)\n",
    "        # pprint(meta.get(b\"path\").decode('utf-8'))\n",
    "        # pprint(meta.get(b\"delimiter\").decode('utf-8'))\n",
    "        read_opts = arrow.csv.ReadOptions(column_names = self.column_names,\n",
    "                                          block_size = self.block_size,\n",
    "                                          autogenerate_column_names = bool)\n",
    "        parse_opts = arrow.csv.ParseOptions(delimiter = delimiter)\n",
    "        convert_opts = arrow.csv.ConvertOptions(column_types = self.schema,\n",
    "                                                include_columns = self.column_names)\n",
    "        self.reader = arrow.csv.open_csv(path,read_options = read_opts,parse_options = parse_opts,convert_options = convert_opts)\n",
    "\n",
    "    def Next(self):\n",
    "        try:\n",
    "            chunk = self.reader.read_next_batch()\n",
    "            needed_arrays = []\n",
    "            for col_idx in range(chunk.num_columns):\n",
    "                if col_idx in self.drop_columns:\n",
    "                    continue\n",
    "                needed_arrays.append(chunk.column(col_idx))\n",
    "            # pprint(self.schema)\n",
    "            # pprint(needed_arrays)\n",
    "            ret_chunk = arrow.RecordBatch.from_arrays(needed_arrays,self.column_names,self.schema)\n",
    "            return ret_chunk\n",
    "        except StopIteration:\n",
    "            return None\n",
    "\n",
    "    def Close(self):\n",
    "        self.reader.close()\n",
    "        self.reader = None\n",
    "        self.schema = None\n",
    "        self.column_names = None\n",
    "        self.drop_columns = None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    l_orderkey  l_partkey  l_suppkey  l_linenumber l_quantity l_extendedprice  \\\n",
      "0            1      15519        785             1      17.00        24386.67   \n",
      "1            1       6731        732             2      36.00        58958.28   \n",
      "2            1       6370        371             3       8.00        10210.96   \n",
      "3            1        214        465             4      28.00        31197.88   \n",
      "4            1       2403        160             5      24.00        31329.60   \n",
      "..         ...        ...        ...           ...        ...             ...   \n",
      "95          97       4957        212             2      37.00        68892.15   \n",
      "96          97       7770        542             3      19.00        31877.63   \n",
      "97          98       4022         23             1      28.00        25928.56   \n",
      "98          98      10975        756             2       1.00         1885.97   \n",
      "99          98       4471        472             3      14.00        19256.58   \n",
      "\n",
      "   l_discount l_tax l_returnflag l_linestatus  l_shipdate l_commitdate  \\\n",
      "0        0.04  0.02            N            O  1996-03-13   1996-02-12   \n",
      "1        0.09  0.06            N            O  1996-04-12   1996-02-28   \n",
      "2        0.10  0.02            N            O  1996-01-29   1996-03-05   \n",
      "3        0.09  0.06            N            O  1996-04-21   1996-03-30   \n",
      "4        0.10  0.04            N            O  1996-03-30   1996-03-14   \n",
      "..        ...   ...          ...          ...         ...          ...   \n",
      "95       0.02  0.06            A            F  1993-04-13   1993-03-30   \n",
      "96       0.06  0.08            R            F  1993-05-14   1993-03-05   \n",
      "97       0.06  0.07            A            F  1994-12-24   1994-10-25   \n",
      "98       0.00  0.00            A            F  1994-12-01   1994-12-12   \n",
      "99       0.05  0.02            A            F  1994-12-30   1994-11-22   \n",
      "\n",
      "   l_receiptdate     l_shipinstruct l_shipmode  \\\n",
      "0     1996-03-22  DELIVER IN PERSON      TRUCK   \n",
      "1     1996-04-20   TAKE BACK RETURN       MAIL   \n",
      "2     1996-01-31   TAKE BACK RETURN    REG AIR   \n",
      "3     1996-05-16               NONE        AIR   \n",
      "4     1996-04-01               NONE        FOB   \n",
      "..           ...                ...        ...   \n",
      "95    1993-04-14  DELIVER IN PERSON       SHIP   \n",
      "96    1993-05-25   TAKE BACK RETURN       RAIL   \n",
      "97    1995-01-16        COLLECT COD    REG AIR   \n",
      "98    1994-12-15  DELIVER IN PERSON      TRUCK   \n",
      "99    1995-01-27        COLLECT COD        AIR   \n",
      "\n",
      "                                    l_comment  \n",
      "0                     egular courts above the  \n",
      "1          ly final dependencies: slyly bold   \n",
      "2               riously. regular, express dep  \n",
      "3                     lites. fluffily even de  \n",
      "4                     pending foxes. slyly re  \n",
      "..                                        ...  \n",
      "95           ic requests boost carefully quic  \n",
      "96  gifts. furiously ironic packages cajole.   \n",
      "97                pending, regular accounts s  \n",
      "98             . unusual instructions against  \n",
      "99   cajole furiously. blithely ironic ideas   \n",
      "\n",
      "[100 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "csvReader = CsvTableScan(lineitemSchema,None,[16])\n",
    "csvReader.Open()\n",
    "record1 = csvReader.Next()\n",
    "pprint(record1.to_pandas())\n",
    "csvReader.Close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 表达式执行函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "outputs": [],
   "source": [
    "def exec_expr(expr,records,agg_offset):\n",
    "    expr_type = expr[0]\n",
    "    if expr_type == EXPR_OP_COLUMN_REF:\n",
    "        return records.column(expr[1][0].name)\n",
    "    elif expr_type == EXPR_OP_CONST:\n",
    "        if expr[1]:# NULL\n",
    "            raise Exception(f\"not implement const NULL\")\n",
    "        else:\n",
    "            if isinstance(expr[2],ast.String):\n",
    "                return arrow.array([expr[2].sval]*records.num_rows,arrow.string())\n",
    "            elif isinstance(expr[2],ast.Integer):\n",
    "                return arrow.array([expr[2].ival]*records.num_rows,arrow.int32())\n",
    "            else:\n",
    "                raise Exception(f\"not implement const expr {expr}\")\n",
    "    elif expr_type == EXPR_OP_CAST:\n",
    "        #直接转换\n",
    "        l = exec_expr(expr[1],records,agg_offset)\n",
    "        target_type = expr[2][0].sval\n",
    "        if len(expr[2]) > 1:\n",
    "            target_type = expr[2][1].sval\n",
    "        if target_type == \"date\":\n",
    "            date_vals = []\n",
    "            for s in l:\n",
    "                date_vals.append(datetime.strptime(str(s),\"%Y-%m-%d\"))\n",
    "            return arrow.array(date_vals,arrow.date32())\n",
    "        elif target_type == \"interval\":\n",
    "            int_vals = []\n",
    "            for s in l:\n",
    "                int_vals.append(int(str(s)))\n",
    "            return arrow.array(int_vals,arrow.int32())\n",
    "        else:\n",
    "            print(f\"target_type {target_type}\")\n",
    "            return compute.cast(l,target_type)\n",
    "    elif expr_type == EXPR_OP_PLUS:\n",
    "        l = exec_expr(expr[1],records,agg_offset)\n",
    "        r = exec_expr(expr[2],records,agg_offset)\n",
    "        return compute.add(l,r)\n",
    "    elif expr_type == EXPR_OP_MINUS:\n",
    "        l = exec_expr(expr[1],records,agg_offset)\n",
    "        r = exec_expr(expr[2],records,agg_offset)\n",
    "\n",
    "        if types.is_date32(l.type):\n",
    "            #对时间的减法做特殊处理\n",
    "            date_time_vals = []\n",
    "            for d in l:\n",
    "                date_time_vals.append(datetime.strptime(str(d),\"%Y-%m-%d\"))\n",
    "            time_delta_vals = []\n",
    "            if types.is_int32(r.type):\n",
    "                for i in r:\n",
    "                    time_delta_vals.append(timedelta(int(str(i))))\n",
    "            else:\n",
    "                raise Exception(\"date minus needs int32\")\n",
    "\n",
    "            res_vals = [date_time_vals[i] - time_delta_vals[i] for i in range(len(time_delta_vals))]\n",
    "            return arrow.array(res_vals,arrow.date32())\n",
    "        else:\n",
    "            return compute.subtract(l,r)\n",
    "    elif expr_type == EXPR_OP_MULTI:\n",
    "        l = exec_expr(expr[1],records,agg_offset)\n",
    "        r = exec_expr(expr[2],records,agg_offset)\n",
    "        return compute.multiply(l,r)\n",
    "    elif expr_type == EXPR_OP_LESS_EQUAL:\n",
    "        l = exec_expr(expr[1],records,agg_offset)\n",
    "        r = exec_expr(expr[2],records,agg_offset)\n",
    "        return compute.less_equal(l,r)\n",
    "    elif expr_type == GROUP_EXPR:\n",
    "        return exec_expr(expr[1],records,agg_offset)\n",
    "    elif expr_type == OUTPUT_EXPR:\n",
    "        return exec_expr(expr[2],records,agg_offset)\n",
    "    elif expr_type == FUNC_RESULT_REF_EXPR:\n",
    "        return records.column(expr[1]+agg_offset)\n",
    "    elif expr_type == PROJECT_EXPR:\n",
    "        return records.column(expr[1])\n",
    "    else:\n",
    "        raise Exception(f\"not implement exec expr {expr}\")\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## filter执行器\n",
    "执行where子句"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 执行器实现"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "outputs": [],
   "source": [
    "class FilterExecutor(Executor):\n",
    "    def __init__(self, filter: tuple, child: Executor):\n",
    "        super().__init__()\n",
    "        self.filter = filter\n",
    "        self.child = child\n",
    "\n",
    "    def Open(self):\n",
    "        self.child.Open()\n",
    "\n",
    "    def Next(self):\n",
    "        child_records = self.child.Next()\n",
    "        if child_records is None:\n",
    "            return None\n",
    "        mask = exec_expr(self.filter,child_records,0)\n",
    "        return child_records.filter(mask)\n",
    "\n",
    "    def Close(self):\n",
    "        self.child.Close()\n",
    "        self.filter = None\n",
    "        self.child = None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 测试时间减法"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "date1 = datetime.strptime('1998-12-01',\"%Y-%m-%d\")\n",
    "date2_arr = arrow.array([date1]*2,arrow.date32())\n",
    "# pprint(date2_arr)\n",
    "date4_vals = []\n",
    "if types.is_date32(date2_arr.type):\n",
    "    for d in date2_arr:\n",
    "        print(datetime.strptime(str(d),\"%Y-%m-%d\"))\n",
    "\n",
    "date3_arr = arrow.array([112]*2,arrow.int32())\n",
    "if types.is_int32(date3_arr.type):\n",
    "    for i in date3_arr:\n",
    "        print(timedelta(int(str(i))))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## groupby执行器"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 聚合函数中间结果"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "outputs": [],
   "source": [
    "class AggFunc:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def name(self):\n",
    "        pass\n",
    "\n",
    "    def add(self,records,row_idx):\n",
    "        pass\n",
    "\n",
    "    def addRecords(self,records):\n",
    "        pass\n",
    "\n",
    "    def merge(self,other):\n",
    "        pass\n",
    "\n",
    "    def get(self):\n",
    "        pass\n",
    "\n",
    "class AggFuncFactory:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def create(self,name):\n",
    "        if name == \"sum\":\n",
    "            return AggFuncSum()\n",
    "        elif name == \"count\":\n",
    "            return AggFuncCount()\n",
    "        elif name == \"avg\":\n",
    "            return AggFuncAvg()\n",
    "        else:\n",
    "            raise Exception(f\"not implement agg func {name}\")\n",
    "\n",
    "class AggFuncSum(AggFunc):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sum = None\n",
    "\n",
    "    def name(self):\n",
    "        return \"sum\"\n",
    "\n",
    "    def add(self,records,row_idx):\n",
    "        param_val = records[0][row_idx]\n",
    "        if self.sum is None:\n",
    "            self.sum = param_val\n",
    "        else:\n",
    "            compute.add(self.sum,param_val)\n",
    "\n",
    "    def addRecords(self,records):\n",
    "        pass\n",
    "\n",
    "    def merge(self,other):\n",
    "        pass\n",
    "\n",
    "    def get(self):\n",
    "        return self.sum\n",
    "\n",
    "class AggFuncCount(AggFunc):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.count = 0\n",
    "\n",
    "    def name(self):\n",
    "        return \"count\"\n",
    "\n",
    "    def add(self,records,row_idx):\n",
    "        self.count = self.count + 1\n",
    "\n",
    "    def addRecords(self,records):\n",
    "        pass\n",
    "\n",
    "    def merge(self,other):\n",
    "        pass\n",
    "\n",
    "    def get(self):\n",
    "        return self.count\n",
    "\n",
    "class AggFuncAvg(AggFunc):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.count = 0\n",
    "        self.sum = None\n",
    "\n",
    "    def name(self):\n",
    "        return \"avg\"\n",
    "\n",
    "    def add(self,records,row_idx):\n",
    "        param_val = records[0][row_idx]\n",
    "        if self.sum is None:\n",
    "            self.sum = param_val\n",
    "        else:\n",
    "            compute.add(self.sum,param_val)\n",
    "        self.count = self.count + 1\n",
    "\n",
    "    def addRecords(self,records):\n",
    "        pass\n",
    "\n",
    "    def merge(self,other):\n",
    "        pass\n",
    "\n",
    "    def get(self):\n",
    "        return compute.divide(self.sum , self.count)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 取groupby的Field"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "outputs": [],
   "source": [
    "def get_field_from_groupby(e):\n",
    "    typ = e[1][0]\n",
    "    if typ == EXPR_OP_COLUMN_REF:\n",
    "        return e[1][1][0]\n",
    "    else:\n",
    "        raise Exception(f\"not implement group by {e}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 确定scalar的类型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "outputs": [],
   "source": [
    "def get_field_from_value(s):\n",
    "    if isinstance(s,arrow.StringScalar):\n",
    "        return s.type\n",
    "    elif isinstance(s,arrow.Decimal256Scalar):\n",
    "        return s.type\n",
    "    elif isinstance(s,arrow.Int64Scalar):\n",
    "        return s.type\n",
    "    elif isinstance(s,int):\n",
    "        return arrow.int64()\n",
    "    elif isinstance(s,str):\n",
    "        return arrow.string()\n",
    "    else:\n",
    "        raise Exception(f\"not implement scalar type {s} {type(s)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 数据列转成array"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "outputs": [],
   "source": [
    "def convert_col_to_array(col,typ):\n",
    "    if isinstance(col[0],arrow.StringScalar):\n",
    "        return arrow.array([ss.as_py() for ss in col],typ)\n",
    "    elif isinstance(col[0],arrow.Decimal256Scalar):\n",
    "        return arrow.array([ss.as_py() for ss in col],typ)\n",
    "    elif isinstance(col[0],int):\n",
    "        return arrow.array(col,typ)\n",
    "    elif isinstance(col[0],str):\n",
    "        return arrow.array(col,typ)\n",
    "    else:\n",
    "        raise Exception(f\"not implement col type {col}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 执行器实现"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "outputs": [],
   "source": [
    "class GroupbyExecutor(Executor):\n",
    "    def __init__(self, plan: dict, child: Executor):\n",
    "        super().__init__()\n",
    "        self.plan = plan\n",
    "        self.child = child\n",
    "        self.aggregate = plan.get(AGGREGATE,[])\n",
    "        self.groupby = plan.get(GROUP,[])\n",
    "        self.output = plan.get(OUTPUT,[])\n",
    "        self.hash_func = hashlib.sha256()\n",
    "        #构建哈希表\n",
    "        self.hash_table = {}\n",
    "        self.agg_factory = AggFuncFactory()\n",
    "\n",
    "    def gen_hash(self,records):\n",
    "        hash_vals = []\n",
    "        for input in records:\n",
    "            self.hash_func.update(str(input).encode(\"utf-8\"))\n",
    "            val = self.hash_func.hexdigest()\n",
    "            # print(input,type(val))\n",
    "            hash_vals.append(val)\n",
    "        return hash_vals\n",
    "\n",
    "    def update_agg_func_val(self,hash_key,group_by_vals,param_vals,row_idx):\n",
    "        #取聚合函数中间结果\n",
    "        hash_val = self.hash_table.get(hash_key,[])\n",
    "        if len(hash_val) == 0:\n",
    "            agg_func_vals = []\n",
    "            for agg_func_expr in self.aggregate:\n",
    "                agg_func_name = agg_func_expr[1]\n",
    "                intermediate_result = self.agg_factory.create(agg_func_name)\n",
    "                agg_func_vals.append(intermediate_result)\n",
    "            group_by_row_vals = []\n",
    "            for v in group_by_vals:\n",
    "                group_by_row_vals.append(v[row_idx])\n",
    "            # groupby1, groupby2, ..., agg1,agg2, ...,\n",
    "            hash_val = [group_by_row_vals,agg_func_vals]\n",
    "            self.hash_table[hash_key] = hash_val\n",
    "\n",
    "        #更新聚合函数中间结果\n",
    "        for agg_idx in range(len(self.aggregate)):\n",
    "            agg_func_val = hash_val[1][agg_idx]\n",
    "            param_val = param_vals[agg_idx]\n",
    "            # pprint(agg_func_val)\n",
    "            # print(f\"func name {agg_func_val.name()}\")\n",
    "            agg_func_val.add(param_val,row_idx)\n",
    "\n",
    "\n",
    "    def end_agg_func_val(self):\n",
    "        # print(f\"hash_table {self.hash_table}\")\n",
    "        # groupby1, groupby2, ..., agg1,agg2,...,\n",
    "        result_cols = []\n",
    "        for hash_key,hash_val in self.hash_table.items():\n",
    "            if len(result_cols) == 0:\n",
    "                result_cols = [[] for _ in range(len(hash_val[0]) + len(hash_val[1]))]\n",
    "            # print(hash_key)\n",
    "            # for agg_func_val in agg_func_vals:\n",
    "            #     print(agg_func_val)\n",
    "            # pprint(len(hash_val[0]))\n",
    "            # pprint(len(hash_val[1]))\n",
    "            # pprint(result_cols)\n",
    "            #拼接group_by\n",
    "            for i in range(len(hash_val[0])):\n",
    "                result_cols[i].append(hash_val[0][i])\n",
    "\n",
    "            ##拼接聚合函数结果\n",
    "            begin = len(hash_val[0])\n",
    "            for i in range(len(hash_val[1])):\n",
    "                j = begin + i\n",
    "                result_cols[j].append(hash_val[1][i].get())\n",
    "\n",
    "        # pprint(result_cols)\n",
    "        # 定义schema，此处直接拿第一行的结果类型。\n",
    "        # 正确的做法应该是类型推断\n",
    "\n",
    "        result_types = []\n",
    "        for i in range(len(result_cols)):\n",
    "            col = result_cols[i]\n",
    "            v = col[0]\n",
    "            # pprint(v)\n",
    "            if i < len(self.groupby):\n",
    "                result_types.append(get_field_from_groupby(self.groupby[i]))\n",
    "            else:\n",
    "                t = get_field_from_value(v)\n",
    "                result_types.append((str(i - len(self.groupby)),t))\n",
    "            # arr = arrow.array(col)\n",
    "            # result_arr.append(arr)\n",
    "        schema = arrow.schema(result_types)\n",
    "        # pprint(schema)\n",
    "\n",
    "        #确定数据\n",
    "        result_arr = []\n",
    "        for i in range(len(result_cols)):\n",
    "            col = result_cols[i]\n",
    "            result_arr.append(convert_col_to_array(col,schema.field(i).type))\n",
    "        # pprint(result_arr)\n",
    "        return arrow.record_batch(result_arr,schema)\n",
    "\n",
    "    def update_hash_table(self,group_by_vals,hash_vals,records):\n",
    "        # 计算聚合函数参数表达式\n",
    "        all_arg_vals = []\n",
    "        for agg_idx in range(len(self.aggregate)):\n",
    "            agg_func = self.aggregate[agg_idx]\n",
    "            # pprint(f\"agg_func {agg_func}\")\n",
    "            # 计算聚合函数每个参数\n",
    "            agg_func_name = agg_func[1]\n",
    "            agg_args = agg_func[2]\n",
    "            agg_arg_vals = []\n",
    "            for arg in agg_args:\n",
    "                # pprint(f\"agg arg {arg}\")\n",
    "                if agg_func_name == \"count\" and arg == \"*\":\n",
    "                    agg_arg_vals.append(arrow.array([\"*\"]*records.num_rows,arrow.string()))\n",
    "                else:\n",
    "                    agg_arg_val = exec_expr(arg,records,0)\n",
    "                    agg_arg_vals.append(agg_arg_val)\n",
    "            all_arg_vals.append(agg_arg_vals)\n",
    "\n",
    "        # pprint(f\"param_vals {param_vals}\")\n",
    "\n",
    "        # pprint(f\"hash_vals {hash_vals}\")\n",
    "        # 根据哈希key分组\n",
    "        row_count = len(group_by_vals[0])\n",
    "        col_count = len(group_by_vals)\n",
    "        for r in range(row_count):\n",
    "            hash_key = []\n",
    "            for c in range(col_count):\n",
    "                hash_key.append(hash_vals[c][r])\n",
    "            #更新聚合函数的中间结果\n",
    "            self.update_agg_func_val(\",\".join(hash_key),group_by_vals,all_arg_vals,r)\n",
    "\n",
    "    def Open(self):\n",
    "        self.child.Open()\n",
    "\n",
    "    def Next(self):\n",
    "        records = self.child.Next()\n",
    "        if records is None:\n",
    "            return None\n",
    "        while records is not None:\n",
    "            # 计算groupby表达式\n",
    "            group_by_vals = []\n",
    "            group_by_hash_vals = []\n",
    "            for e in self.groupby:\n",
    "                # pprint(e)\n",
    "                val = exec_expr(e,records,0)\n",
    "                hash_val = self.gen_hash(val)\n",
    "                group_by_vals.append(val)\n",
    "                group_by_hash_vals.append(hash_val)\n",
    "            # pprint(group_by_hash_vals)\n",
    "            self.update_hash_table(group_by_vals,group_by_hash_vals,records)\n",
    "            # 下一批输入\n",
    "            records = self.child.Next()\n",
    "\n",
    "        #拼接聚合函数结果\n",
    "        # groupby1, groupby2, ..., agg1,agg2,...,\n",
    "        agg_records = self.end_agg_func_val()\n",
    "\n",
    "        #计算output list的值\n",
    "        output_vals = []\n",
    "        output_types = []\n",
    "        for e in self.output:\n",
    "            val = exec_expr(e,agg_records,len(self.groupby))\n",
    "            output_vals.append(val)\n",
    "            output_types.append((e[1],get_field_from_value(val[0])))\n",
    "\n",
    "        #pprint(output_vals)\n",
    "        output_schema = arrow.schema(output_types)\n",
    "        output_records = arrow.record_batch(output_vals,output_schema)\n",
    "        csv.write_csv(output_records,\"group.csv\")\n",
    "        return output_records\n",
    "\n",
    "    def Close(self):\n",
    "        self.child.Close()\n",
    "        self.plan = None\n",
    "        self.child = None\n",
    "        self.aggregate = None\n",
    "        self.groupby = None\n",
    "        self.output = None\n",
    "        self.hash_func = None\n",
    "        self.hash_table = None\n",
    "        self.agg_factory = None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## orderby执行器"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 取排序表达式"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "outputs": [],
   "source": [
    "def get_sort_key_name(e):\n",
    "    typ = e[0]\n",
    "    if typ == EXPR_OP_COLUMN_REF:\n",
    "        return e[1][0].name\n",
    "    else:\n",
    "        raise Exception(f\"not implement sort key name {e}\")\n",
    "\n",
    "def get_sort_keys(orderby):\n",
    "    sorts =[]\n",
    "    for e in orderby:\n",
    "        name = get_sort_key_name(e[1])\n",
    "        dir = \"ascending\"\n",
    "        if e[2] == enums.parsenodes.SortByDir.SORTBY_DESC:\n",
    "            dir = \"descending\"\n",
    "        # print(name,dir)\n",
    "        sorts.append((name,dir))\n",
    "    return sorts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 执行器实现"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "outputs": [],
   "source": [
    "class OrderbyExecutor(Executor):\n",
    "    def __init__(self,plan,child):\n",
    "        super().__init__()\n",
    "        self.plan = plan\n",
    "        self.child = child\n",
    "        self.orderby = plan.get(ORDER,[])\n",
    "\n",
    "    def Open(self):\n",
    "        self.child.Open()\n",
    "\n",
    "    def Next(self):\n",
    "        records = self.child.Next()\n",
    "        if records is None:\n",
    "            return None\n",
    "\n",
    "        #取排序字段\n",
    "        sort_keys = get_sort_keys(self.orderby)\n",
    "        #排序并获取排序后的索引\n",
    "        indices = compute.sort_indices(records,sort_keys)\n",
    "        # pprint(indices)\n",
    "        #按排序索引重新行顺序\n",
    "        return compute.take(records,indices)\n",
    "\n",
    "    def Close(self):\n",
    "        self.child.Close()\n",
    "        self.plan = None\n",
    "        self.child= None\n",
    "        self.orderby = None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## project list执行器"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "outputs": [],
   "source": [
    "class ProjectListExecutor(Executor):\n",
    "    def __init__(self,plan,child):\n",
    "        super().__init__()\n",
    "        self.plan = plan\n",
    "        self.child = child\n",
    "        self.project_list = plan.get(PROJECT,[])\n",
    "\n",
    "    def Open(self):\n",
    "        self.child.Open()\n",
    "\n",
    "    def Next(self):\n",
    "        records = self.child.Next()\n",
    "        if records is None:\n",
    "            return records\n",
    "\n",
    "        #计算project list的值\n",
    "        project_vals = []\n",
    "        project_types = []\n",
    "        for e in self.project_list:\n",
    "            val = exec_expr(e,records,0)\n",
    "            project_vals.append(val)\n",
    "            project_types.append((e[1],get_field_from_value(val[0])))\n",
    "\n",
    "        schema = arrow.schema(project_types)\n",
    "        project_records = arrow.record_batch(project_vals,schema)\n",
    "        return project_records\n",
    "\n",
    "    def Close(self):\n",
    "        self.child.Close()\n",
    "        self.plan = None\n",
    "        self.child= None\n",
    "        self.project_list = None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# main"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 查看tpch q1逻辑计划"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aggregate': [('func',\n",
      "                'sum',\n",
      "                [('colRef',\n",
      "                  (pyarrow.Field<l_quantity: decimal256(21, 2) not null>,\n",
      "                   'tpch',\n",
      "                   'lineitem'))]),\n",
      "               ('func',\n",
      "                'sum',\n",
      "                [('colRef',\n",
      "                  (pyarrow.Field<l_extendedprice: decimal256(21, 2) not null>,\n",
      "                   'tpch',\n",
      "                   'lineitem'))]),\n",
      "               ('func',\n",
      "                'sum',\n",
      "                [('*',\n",
      "                  ('colRef',\n",
      "                   (pyarrow.Field<l_extendedprice: decimal256(21, 2) not null>,\n",
      "                    'tpch',\n",
      "                    'lineitem')),\n",
      "                  ('-',\n",
      "                   ('const', False, <Integer ival=1>),\n",
      "                   ('colRef',\n",
      "                    (pyarrow.Field<l_discount: decimal256(21, 2) not null>,\n",
      "                     'tpch',\n",
      "                     'lineitem'))))]),\n",
      "               ('func',\n",
      "                'sum',\n",
      "                [('*',\n",
      "                  ('*',\n",
      "                   ('colRef',\n",
      "                    (pyarrow.Field<l_extendedprice: decimal256(21, 2) not null>,\n",
      "                     'tpch',\n",
      "                     'lineitem')),\n",
      "                   ('-',\n",
      "                    ('const', False, <Integer ival=1>),\n",
      "                    ('colRef',\n",
      "                     (pyarrow.Field<l_discount: decimal256(21, 2) not null>,\n",
      "                      'tpch',\n",
      "                      'lineitem')))),\n",
      "                  ('+',\n",
      "                   ('const', False, <Integer ival=1>),\n",
      "                   ('colRef',\n",
      "                    (pyarrow.Field<l_tax: decimal256(21, 2) not null>,\n",
      "                     'tpch',\n",
      "                     'lineitem'))))]),\n",
      "               ('func',\n",
      "                'avg',\n",
      "                [('colRef',\n",
      "                  (pyarrow.Field<l_quantity: decimal256(21, 2) not null>,\n",
      "                   'tpch',\n",
      "                   'lineitem'))]),\n",
      "               ('func',\n",
      "                'avg',\n",
      "                [('colRef',\n",
      "                  (pyarrow.Field<l_extendedprice: decimal256(21, 2) not null>,\n",
      "                   'tpch',\n",
      "                   'lineitem'))]),\n",
      "               ('func',\n",
      "                'avg',\n",
      "                [('colRef',\n",
      "                  (pyarrow.Field<l_discount: decimal256(21, 2) not null>,\n",
      "                   'tpch',\n",
      "                   'lineitem'))]),\n",
      "               ('func', 'count', '*'),\n",
      "               ('func',\n",
      "                'sum',\n",
      "                [('colRef',\n",
      "                  (pyarrow.Field<l_quantity: decimal256(21, 2) not null>,\n",
      "                   'tpch',\n",
      "                   'lineitem'))]),\n",
      "               ('func',\n",
      "                'sum',\n",
      "                [('colRef',\n",
      "                  (pyarrow.Field<l_extendedprice: decimal256(21, 2) not null>,\n",
      "                   'tpch',\n",
      "                   'lineitem'))]),\n",
      "               ('func',\n",
      "                'sum',\n",
      "                [('*',\n",
      "                  ('colRef',\n",
      "                   (pyarrow.Field<l_extendedprice: decimal256(21, 2) not null>,\n",
      "                    'tpch',\n",
      "                    'lineitem')),\n",
      "                  ('-',\n",
      "                   ('const', False, <Integer ival=1>),\n",
      "                   ('colRef',\n",
      "                    (pyarrow.Field<l_discount: decimal256(21, 2) not null>,\n",
      "                     'tpch',\n",
      "                     'lineitem'))))]),\n",
      "               ('func',\n",
      "                'sum',\n",
      "                [('*',\n",
      "                  ('*',\n",
      "                   ('colRef',\n",
      "                    (pyarrow.Field<l_extendedprice: decimal256(21, 2) not null>,\n",
      "                     'tpch',\n",
      "                     'lineitem')),\n",
      "                   ('-',\n",
      "                    ('const', False, <Integer ival=1>),\n",
      "                    ('colRef',\n",
      "                     (pyarrow.Field<l_discount: decimal256(21, 2) not null>,\n",
      "                      'tpch',\n",
      "                      'lineitem')))),\n",
      "                  ('+',\n",
      "                   ('const', False, <Integer ival=1>),\n",
      "                   ('colRef',\n",
      "                    (pyarrow.Field<l_tax: decimal256(21, 2) not null>,\n",
      "                     'tpch',\n",
      "                     'lineitem'))))]),\n",
      "               ('func',\n",
      "                'avg',\n",
      "                [('colRef',\n",
      "                  (pyarrow.Field<l_quantity: decimal256(21, 2) not null>,\n",
      "                   'tpch',\n",
      "                   'lineitem'))]),\n",
      "               ('func',\n",
      "                'avg',\n",
      "                [('colRef',\n",
      "                  (pyarrow.Field<l_extendedprice: decimal256(21, 2) not null>,\n",
      "                   'tpch',\n",
      "                   'lineitem'))]),\n",
      "               ('func',\n",
      "                'avg',\n",
      "                [('colRef',\n",
      "                  (pyarrow.Field<l_discount: decimal256(21, 2) not null>,\n",
      "                   'tpch',\n",
      "                   'lineitem'))]),\n",
      "               ('func', 'count', '*')],\n",
      " 'group': [('group_expr',\n",
      "            ('colRef',\n",
      "             (pyarrow.Field<l_returnflag: string not null>,\n",
      "              'tpch',\n",
      "              'lineitem'))),\n",
      "           ('group_expr',\n",
      "            ('colRef',\n",
      "             (pyarrow.Field<l_linestatus: string not null>,\n",
      "              'tpch',\n",
      "              'lineitem')))],\n",
      " 'order': [('order_expr',\n",
      "            ('colRef',\n",
      "             (pyarrow.Field<l_returnflag: string not null>,\n",
      "              'tpch',\n",
      "              'lineitem')),\n",
      "            <SortByDir.SORTBY_DEFAULT: 0>),\n",
      "           ('order_expr',\n",
      "            ('colRef',\n",
      "             (pyarrow.Field<l_linestatus: string not null>,\n",
      "              'tpch',\n",
      "              'lineitem')),\n",
      "            <SortByDir.SORTBY_DEFAULT: 0>)],\n",
      " 'output': [('output_expr',\n",
      "             'l_returnflag',\n",
      "             ('colRef',\n",
      "              (pyarrow.Field<l_returnflag: string not null>,\n",
      "               'tpch',\n",
      "               'lineitem'))),\n",
      "            ('output_expr',\n",
      "             'l_linestatus',\n",
      "             ('colRef',\n",
      "              (pyarrow.Field<l_linestatus: string not null>,\n",
      "               'tpch',\n",
      "               'lineitem'))),\n",
      "            ('output_expr', 'sum_qty', ('func_result_ref', 0)),\n",
      "            ('output_expr', 'sum_base_price', ('func_result_ref', 1)),\n",
      "            ('output_expr', 'sum_disc_price', ('func_result_ref', 2)),\n",
      "            ('output_expr', 'sum_charge', ('func_result_ref', 3)),\n",
      "            ('output_expr', 'avg_qty', ('func_result_ref', 4)),\n",
      "            ('output_expr', 'avg_price', ('func_result_ref', 5)),\n",
      "            ('output_expr', 'avg_disc', ('func_result_ref', 6)),\n",
      "            ('output_expr', 'count_order', ('func_result_ref', 7))],\n",
      " 'project': [('project_expr', 'l_returnflag'),\n",
      "             ('project_expr', 'l_linestatus'),\n",
      "             ('project_expr', 'sum_qty'),\n",
      "             ('project_expr', 'sum_base_price'),\n",
      "             ('project_expr', 'sum_disc_price'),\n",
      "             ('project_expr', 'sum_charge'),\n",
      "             ('project_expr', 'avg_qty'),\n",
      "             ('project_expr', 'avg_price'),\n",
      "             ('project_expr', 'avg_disc'),\n",
      "             ('project_expr', 'count_order')],\n",
      " 'relations': ['singleRelation',\n",
      "               {'lineitem': ['table',\n",
      "                             'tpch',\n",
      "                             'lineitem',\n",
      "                             'lineitem',\n",
      "                             l_orderkey: int64 not null\n",
      "l_partkey: int32 not null\n",
      "l_suppkey: int32 not null\n",
      "l_linenumber: int32 not null\n",
      "l_quantity: decimal256(21, 2) not null\n",
      "l_extendedprice: decimal256(21, 2) not null\n",
      "l_discount: decimal256(21, 2) not null\n",
      "l_tax: decimal256(21, 2) not null\n",
      "l_returnflag: string not null\n",
      "l_linestatus: string not null\n",
      "l_shipdate: date32[day] not null\n",
      "l_commitdate: date32[day] not null\n",
      "l_receiptdate: date32[day] not null\n",
      "l_shipinstruct: string not null\n",
      "l_shipmode: string not null\n",
      "l_comment: string not null\n",
      "-- schema metadata --\n",
      "name: 'lineitem'\n",
      "delimiter: '|'\n",
      "path: '/Users/pengzhen/Documents/GitHub/mo-test/tpch100M/lineitem.tbl_100']}],\n",
      " 'where': ('<=',\n",
      "           ('colRef',\n",
      "            (pyarrow.Field<l_shipdate: date32[day] not null>,\n",
      "             'tpch',\n",
      "             'lineitem')),\n",
      "           ('-',\n",
      "            ('cast',\n",
      "             ('const', False, <String sval='1998-12-01'>),\n",
      "             (<String sval='date'>,)),\n",
      "            ('cast',\n",
      "             ('const', False, <String sval='112'>),\n",
      "             (<String sval='pg_catalog'>, <String sval='interval'>))))}\n"
     ]
    }
   ],
   "source": [
    "plan = {}\n",
    "selBuilder = SelectBuilder()\n",
    "selBuilder.build(q1Stmt.stmt,plan)\n",
    "pprint(plan)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 执行tpch q1物理计划"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   l_returnflag l_linestatus sum_qty sum_base_price sum_disc_price  \\\n",
      "0             A            F   27.00       47461.68     44613.9792   \n",
      "1             A            F    2.00        3681.86      3645.0414   \n",
      "2             A            F   26.00       29151.46     26236.3140   \n",
      "3             A            F   50.00       82887.50     76256.5000   \n",
      "4             A            F   37.00       69484.52     63925.7584   \n",
      "..          ...          ...     ...            ...            ...   \n",
      "91            R            F    1.00        1898.98      1842.0106   \n",
      "92            R            F   37.00       59855.27     54468.2957   \n",
      "93            R            F   30.00       43575.90     43140.1410   \n",
      "94            R            F   13.00       24179.22     24179.2200   \n",
      "95            R            F   19.00       31877.63     29964.9722   \n",
      "\n",
      "      sum_charge                    avg_qty                     avg_price  \\\n",
      "0   47736.957744  27.0000000000000000000000  47461.6800000000000000000000   \n",
      "1    3863.743884   2.0000000000000000000000   3681.8600000000000000000000   \n",
      "2   26761.040280  26.0000000000000000000000  29151.4600000000000000000000   \n",
      "3   78544.195000  50.0000000000000000000000  82887.5000000000000000000000   \n",
      "4   65843.531152  37.0000000000000000000000  69484.5200000000000000000000   \n",
      "..           ...                        ...                           ...   \n",
      "91   1934.111130   1.0000000000000000000000   1898.9800000000000000000000   \n",
      "92  56647.027528  37.0000000000000000000000  59855.2700000000000000000000   \n",
      "93  45728.549460  30.0000000000000000000000  43575.9000000000000000000000   \n",
      "94  24662.804400  13.0000000000000000000000  24179.2200000000000000000000   \n",
      "95  32362.169976  19.0000000000000000000000  31877.6300000000000000000000   \n",
      "\n",
      "                    avg_disc  count_order  \n",
      "0   0.0600000000000000000000            1  \n",
      "1   0.0100000000000000000000            1  \n",
      "2   0.1000000000000000000000            1  \n",
      "3   0.0800000000000000000000            1  \n",
      "4   0.0800000000000000000000            1  \n",
      "..                       ...          ...  \n",
      "91  0.0300000000000000000000            1  \n",
      "92  0.0900000000000000000000            1  \n",
      "93  0.0100000000000000000000            1  \n",
      "94                     0E-22            1  \n",
      "95  0.0600000000000000000000            1  \n",
      "\n",
      "[96 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "pplan_builder = PhysicalPlanBuilder()\n",
    "exec = pplan_builder.build(plan,PROJECT)\n",
    "exec.Open()\n",
    "records = exec.Next()\n",
    "csv.write_csv(records,\"q1.csv\")\n",
    "pprint(records.to_pandas())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "/*### 执行filter方法1*/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "outputs": [],
   "source": [
    "# date1 = datetime.strptime('1998-12-01',\"%Y-%m-%d\")\n",
    "# interval1 = timedelta(1500)\n",
    "# date2 = date1 - interval1\n",
    "# date2_arr = arrow.array([date2]*records.num_rows,arrow.date32())\n",
    "# pprint(date2_arr)\n",
    "# # date1_arr = arrow.array([date1]*records.num_rows,arrow.date32())\n",
    "# # interval_arr = arrow.array([112]*records.num_rows,arrow.int32())\n",
    "# # # arrow 没有时间相减的函数\n",
    "# # date3_arr = compute.subtract(date1_arr,interval_arr)\n",
    "#\n",
    "# #cast1 = compute.cast()\n",
    "# mask1 = compute.less_equal(records.column(\"l_shipdate\"),date2_arr)\n",
    "# pprint(mask1.to_pandas())\n",
    "# res1 = records.filter(mask1)\n",
    "# pprint(res1.to_pandas())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "/*### 执行filter方法2*/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "outputs": [],
   "source": [
    "# table1 = arrow.Table.from_batches([records])\n",
    "# le1 = compute.less_equal(compute.field(\"l_orderkey\"),1)\n",
    "# res2 = table1.filter(le1)\n",
    "# pprint(res2.to_pandas())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "outputs": [],
   "source": [
    "exec.Close()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
